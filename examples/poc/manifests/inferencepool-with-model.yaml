apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferencePool
metadata:
  labels:
  name: vllm-llama2-7b-pool
spec:
  targetPort: 8000
  modelServerSelector:
    "app": "vllm-llama2-7b-pool"
---
apiVersion: inference.networking.x-k8s.io/v1alpha1
kind: InferenceModel
metadata:
  labels:
    app.kubernetes.io/name: api
    app.kubernetes.io/managed-by: kustomize
  name: inferencemodel-sample
spec:
  modelName: sql-lora
  criticality: Critical
  poolRef:
    # this is the default val:
    group: inference.networking.x-k8s.io/v1alpha1
    # this is the default val:
    kind: InferencePool
    name: vllm-llama2-7b-pool
  targetModels:
  - name: sql-lora-1fdg2
    weight: 100

