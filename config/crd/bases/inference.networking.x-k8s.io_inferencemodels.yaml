---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.16.1
  name: inferencemodels.inference.networking.x-k8s.io
spec:
  group: inference.networking.x-k8s.io
  names:
    kind: InferenceModel
    listKind: InferenceModelList
    plural: inferencemodels
    singular: inferencemodel
  scope: Namespaced
  versions:
  - name: v1alpha1
    schema:
      openAPIV3Schema:
        description: InferenceModel is the Schema for the InferenceModels API
        properties:
          apiVersion:
            description: |-
              APIVersion defines the versioned schema of this representation of an object.
              Servers should convert recognized schemas to the latest internal value, and
              may reject unrecognized values.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources
            type: string
          kind:
            description: |-
              Kind is a string value representing the REST resource this object represents.
              Servers may infer this from the endpoint the client submits requests to.
              Cannot be updated.
              In CamelCase.
              More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds
            type: string
          metadata:
            type: object
          spec:
            description: |-
              InferenceModelSpec represents a specific model use case. This resource is
              managed by the "Inference Workload Owner" persona.

              The Inference Workload Owner persona is: a team that trains, verifies, and
              leverages a large language model from a model frontend, drives the lifecycle
              and rollout of new versions of those models, and defines the specific
              performance and latency goals for the model. These workloads are
              expected to operate within an InferencePool sharing compute capacity with other
              InferenceModels, defined by the Inference Platform Admin.

              InferenceModel's modelName (not the ObjectMeta name) is unique for a given InferencePool,
              if the name is reused, an error will be shown on the status of a
              InferenceModel that attempted to reuse. The oldest InferenceModel, based on
              creation timestamp, will be selected to remain valid. In the event of a race
              condition, one will be selected at random.
            properties:
              criticality:
                default: Default
                description: Defines how important it is to serve the model compared
                  to other models referencing the same pool.
                enum:
                - Critical
                - Default
                - Sheddable
                type: string
              modelName:
                description: |-
                  The name of the model as the users set in the "model" parameter in the requests.
                  The name should be unique among the workloads that reference the same backend pool.
                  This is the parameter that will be used to match the request with. In the future, we may
                  allow to match on other request parameters. The other approach to support matching on
                  on other request parameters is to use a different ModelName per HTTPFilter.
                  Names can be reserved without implementing an actual model in the pool.
                  This can be done by specifying a target model and setting the weight to zero,
                  an error will be returned specifying that no valid target model is found.
                maxLength: 253
                type: string
              poolRef:
                description: Reference to the poolIt must exist in the same namespace.
                properties:
                  group:
                    default: inference.networking.x-k8s.io
                    description: Group is the group of the referent.
                    maxLength: 253
                    pattern: ^$|^[a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*$
                    type: string
                  kind:
                    default: InferencePool
                    description: Kind is kind of the referent. For example "InferencePool".
                    maxLength: 63
                    minLength: 1
                    pattern: ^[a-zA-Z]([-a-zA-Z0-9]*[a-zA-Z0-9])?$
                    type: string
                  name:
                    description: Name is the name of the referent.
                    maxLength: 253
                    minLength: 1
                    type: string
                type: object
              targetModels:
                description: |-
                  Allow multiple versions of a model for traffic splitting.
                  If not specified, the target model name is defaulted to the modelName parameter.
                  modelName is often in reference to a LoRA adapter.
                items:
                  description: |-
                    TargetModel represents a deployed model or a LoRA adapter. The
                    Name field is expected to match the name of the LoRA adapter
                    (or base model) as it is registered within the model server. Inference
                    Gateway assumes that the model exists on the model server and is the
                    responsibility of the user to validate a correct match. Should a model fail
                    to exist at request time, the error is processed by the Instance Gateway,
                    and then emitted on the appropriate InferenceModel object.
                  properties:
                    name:
                      description: The name of the adapter as expected by the ModelServer.
                      maxLength: 253
                      type: string
                    weight:
                      default: 1
                      description: |-
                        Weight is used to determine the proportion of traffic that should be
                        sent to this target model when multiple versions of the model are specified.
                      maximum: 1000000
                      minimum: 0
                      type: integer
                  type: object
                maxItems: 10
                minItems: 1
                type: array
            required:
            - poolRef
            type: object
          status:
            description: InferenceModelStatus defines the observed state of InferenceModel
            properties:
              conditions:
                description: Conditions track the state of the InferencePool.
                items:
                  description: Condition contains details for one aspect of the current
                    state of this API Resource.
                  properties:
                    lastTransitionTime:
                      description: |-
                        lastTransitionTime is the last time the condition transitioned from one status to another.
                        This should be when the underlying condition changed.  If that is not known, then using the time when the API field changed is acceptable.
                      format: date-time
                      type: string
                    message:
                      description: |-
                        message is a human readable message indicating details about the transition.
                        This may be an empty string.
                      maxLength: 32768
                      type: string
                    observedGeneration:
                      description: |-
                        observedGeneration represents the .metadata.generation that the condition was set based upon.
                        For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date
                        with respect to the current state of the instance.
                      format: int64
                      minimum: 0
                      type: integer
                    reason:
                      description: |-
                        reason contains a programmatic identifier indicating the reason for the condition's last transition.
                        Producers of specific condition types may define expected values and meanings for this field,
                        and whether the values are considered a guaranteed API.
                        The value should be a CamelCase string.
                        This field may not be empty.
                      maxLength: 1024
                      minLength: 1
                      pattern: ^[A-Za-z]([A-Za-z0-9_,:]*[A-Za-z0-9_])?$
                      type: string
                    status:
                      description: status of the condition, one of True, False, Unknown.
                      enum:
                      - "True"
                      - "False"
                      - Unknown
                      type: string
                    type:
                      description: type of condition in CamelCase or in foo.example.com/CamelCase.
                      maxLength: 316
                      pattern: ^([a-z0-9]([-a-z0-9]*[a-z0-9])?(\.[a-z0-9]([-a-z0-9]*[a-z0-9])?)*/)?(([A-Za-z0-9][-A-Za-z0-9_.]*)?[A-Za-z0-9])$
                      type: string
                  required:
                  - lastTransitionTime
                  - message
                  - reason
                  - status
                  - type
                  type: object
                type: array
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
